# IEEE Fraud Detection Pipeline ğŸ•µï¸â€â™‚ï¸

Un sistema MLOps de detecciÃ³n de fraude modular, escalable y preparado para producciÃ³n ("Production-Ready"), diseÃ±ado para la competiciÃ³n **IEEE-CIS Fraud Detection** de Kaggle.

Este proyecto implementa un pipeline completo desde la ingestiÃ³n de datos crudos hasta la inferencia, utilizando tecnologÃ­as modernas para asegurar reproducibilidad y rendimiento.

## ğŸ— Arquitectura del Proyecto

El cÃ³digo sigue una estructura modular separando configuraciÃ³n, lÃ³gica de negocio y ejecuciÃ³n.

```text
ieee_fraud_detection/
â”œâ”€â”€ data/                   # Datos (Raw, Processed, Submissions) - Ignorado en Git
â”œâ”€â”€ scripts/                # Puntos de entrada (CLI)
â”‚   â””â”€â”€ run_pipeline.py     # Orquestador principal
â”œâ”€â”€ src/                    # LÃ³gica de Negocio (Paquete Python)
â”‚   â”œâ”€â”€ config.py           # ConfiguraciÃ³n tipada (Pydantic)
â”‚   â”œâ”€â”€ preprocess.py       # ETL con PySpark (Train/Test consistencia)
â”‚   â”œâ”€â”€ training.py         # Entrenamiento (XGBoost/LightGBM/CatBoost)
â”‚   â”œâ”€â”€ ensemble.py         # LÃ³gica de validaciÃ³n cruzada
â”‚   â””â”€â”€ inference.py        # GeneraciÃ³n de predicciones
â”œâ”€â”€ requirements.txt        # Dependencias
â””â”€â”€ README.md               # DocumentaciÃ³n
```

## ğŸ›  Stack TecnolÃ³gico

* **ETL & Big Data:** PySpark 3.x (Manejo de grandes volÃºmenes y Feature Engineering).
* **Modelado:** XGBoost (GPU Accelerated), LightGBM, CatBoost.
* **OptimizaciÃ³n:** Optuna (BÃºsqueda Bayesiana de HiperparÃ¡metros).
* **MLOps:** MLflow (Experiment Tracking & Model Registry).
* **ConfiguraciÃ³n:** Pydantic (ValidaciÃ³n de tipos y gestiÃ³n de entornos).

## ğŸš€ Quick Start

### 1. InstalaciÃ³n

Se recomienda usar un entorno virtual con Python 3.10+.

```bash
# Crear entorno (opcional)
conda create -n fraud_detection python=3.10
conda activate fraud_detection

# Instalar dependencias
pip install -r requirements.txt
```

### 2. PreparaciÃ³n de Datos

Descarga los datasets de la competiciÃ³n (train_transaction.csv, train_identity.csv, etc.) y colÃ³calos en: `data/raw/`

### 3. EjecuciÃ³n del Pipeline

El proyecto se controla mediante un Ãºnico script CLI: `scripts/run_pipeline.py`.

**Paso 1: Preprocesamiento (ETL)**

Limpia los datos, genera features temporales, gestiona nulos y crea los archivos Parquet optimizados. Asegura consistencia entre Train y Test.

```bash
python scripts/run_pipeline.py preprocess
```

**Paso 2: Entrenamiento**

Entrena el modelo especificado utilizando GPU. Los experimentos y artefactos se registran automÃ¡ticamente en MLflow.

```bash
# Entrenar XGBoost (Default)
python scripts/run_pipeline.py train --model xgboost

# Entrenar todos los modelos para Ensemble
python scripts/run_pipeline.py train --model all
```

**Paso 3: ValidaciÃ³n (Ensemble Local)**

Carga los modelos registrados y calcula el AUC combinado en el set de validaciÃ³n.

```bash
python scripts/run_pipeline.py ensemble
```

**Paso 4: Inferencia (Kaggle Submission)**

Genera el archivo `submission.csv` final utilizando los modelos entrenados.

```bash
python scripts/run_pipeline.py predict
```

## ğŸ“Š Resultados Actuales

* **Single Model (XGBoost Tuned):** AUC ~0.922 (ValidaciÃ³n Temporal).
* **Hardware:** Optimizado para NVIDIA RTX 4080 / AMD Ryzen 9800X3D.

Proyecto desarrollado para IEEE-CIS Fraud Detection.
